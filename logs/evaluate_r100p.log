nohup: ignoring input
wandb: Currently logged in as: xuanzhu_07 (xuanzhu_07-university-of-sydney). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.19.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.3
wandb: Run data is saved locally in /home/yxma/hzx/hzx/hzx/rand_defence/wandb/run-20250131_212843-0hkvffwt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-capybara-72
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square
wandb: üöÄ View run at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/runs/0hkvffwt
[2025/01/31 21:28:47] - Namespace(batch_size=128, data_dir='~/datasets/CIFAR10/', dataset='cifar100', epochs=200, network='ResNet18', worker=4, lr_schedule='multistep', lr_min=0.0, lr_max=0.1, weight_decay=0.0005, momentum=0.9, none_random_training=True, rand_deform_training=False, randpos_deform_training=True, randpos_multi_deform_training=False, is_n_repeat=False, reNum=5, only_adv_randpos_training=False, rand_path_training=False, epsilon=8, alpha=2, c=0.0001, steps=1000, seed=0, attack_iters=20, restarts=1, save_dir='logs/ResNet18_DeformableConvolution', pretrain='ckpt/cifar100/ResNet18/ckpt/model_20241107183716.pth', continue_training=False, lb=2048, pos=0, eot=False, bapp_iterations=1000, bapp_stepsize='geometric_progression', bapp_max_evals=100, bapp_initial_evals=100, hang=False, device=2)
[2025/01/31 21:28:47] - Dataset: cifar100
/home/yxma/anaconda3/envs/py39_torch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/yxma/anaconda3/envs/py39_torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[2025/01/31 21:28:49] - Evaluating with standard images with random mask...
Process ID: 3755005
Pretrain model path: ckpt/cifar100/ResNet18/ckpt/model_20241107183716.pth
Does pretrain model path exist? True
Files already downloaded and verified
Files already downloaded and verified
ResNetPartmask5(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): ModuleList(
    (0): RandonBasicBlock02(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): MaskedConv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential()
    )
  )
  (layer11): ModuleList(
    (0): BasicBlock(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential()
    )
  )
  (layer2): ModuleList(
    (0): BasicBlock(
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential()
    )
  )
  (layer3): ModuleList(
    (0): BasicBlock(
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential()
    )
  )
  (layer4): ModuleList(
    (0): BasicBlock(
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=100, bias=True)
  (normalize): NormalizeByChannelMeanStd(mean=tensor([0.4914, 0.4822, 0.4465], device='cuda:2'), std=tensor([0.2471, 0.2435, 0.2616], device='cuda:2'))
)
Different keys:
normalize.mean
normalize.std
Nature:
[2025/01/31 21:28:50] - Nature Acc Mean: 0.6479, Std: 0.0000
tensor([[[[0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        ...,


        [[[0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]]], device='cuda:2')
Pixel attacking
[00:00<?,?it/s]/home/yxma/anaconda3/envs/py39_torch/lib/python3.9/site-packages/torchattacks/attacks/_differential_evolution.py:592: RuntimeWarning: divide by zero encountered in scalar divide
  convergence=self.tol / convergence) is True):
[00:11<14:47,11.38s/it][00:31<21:21,16.64s/it][00:49<21:48,17.22s/it][01:12<24:27,19.56s/it][01:28<22:27,18.20s/it][01:45<21:35,17.75s/it][02:07<23:06,19.26s/it][02:25<22:09,18.73s/it][02:48<23:30,20.15s/it][03:02<20:48,18.10s/it][03:13<18:07,15.99s/it][03:33<19:07,17.13s/it][03:46<17:34,15.98s/it][04:02<17:26,16.10s/it][04:22<18:11,17.06s/it][04:36<17:05,16.27s/it][05:00<19:07,18.51s/it][05:17<18:17,18.00s/it][05:40<19:35,19.59s/it][05:59<19:15,19.58s/it][06:17<18:15,18.90s/it][06:41<19:35,20.63s/it][06:55<17:09,18.38s/it][07:14<17:15,18.82s/it][07:29<15:46,17.53s/it][07:43<14:32,16.46s/it][08:03<15:14,17.59s/it][08:20<14:47,17.40s/it][08:42<15:43,18.86s/it][09:01<15:21,18.80s/it][09:22<15:28,19.34s/it][09:40<14:53,19.01s/it][10:01<15:05,19.68s/it][10:20<14:31,19.37s/it][10:35<13:12,18.01s/it][10:54<13:08,18.34s/it][11:08<12:05,17.27s/it][11:32<13:07,19.21s/it][11:52<12:55,19.39s/it][12:12<12:45,19.62s/it][12:34<12:47,20.19s/it][12:49<11:28,18.61s/it][13:13<12:08,20.24s/it][13:27<10:48,18.52s/it][13:49<11:03,19.53s/it][14:08<10:36,19.28s/it][14:25<10:00,18.78s/it][14:43<09:30,18.41s/it][14:57<08:35,17.19s/it][15:17<08:39,17.92s/it][15:32<07:57,17.04s/it][15:43<06:49,15.17s/it][16:07<07:48,18.02s/it][16:29<07:56,19.08s/it][16:51<07:59,19.96s/it][17:02<06:35,17.20s/it][17:24<06:54,18.85s/it][17:41<06:24,18.29s/it][18:01<06:13,18.67s/it][18:23<06:13,19.68s/it][18:43<05:58,19.90s/it][19:05<05:46,20.37s/it][19:21<05:08,19.27s/it][19:46<05:12,20.82s/it][20:05<04:44,20.34s/it][20:29<04:39,21.48s/it][20:47<04:02,20.23s/it][21:07<03:42,20.22s/it][21:24<03:14,19.43s/it][21:43<02:53,19.23s/it][22:09<02:49,21.15s/it][22:28<02:24,20.64s/it][22:52<02:10,21.71s/it][23:09<01:40,20.16s/it][23:36<01:29,22.28s/it][23:59<01:06,22.32s/it][24:18<00:42,21.40s/it][24:38<00:20,20.96s/it][24:41<00:00,15.56s/it][24:41<00:00,18.75s/it][2025/01/31 21:53:32] - pixel - Run 79: Accuracy: 0.5951

[00:00<?,?it/s][00:20<26:43,20.55s/it][00:41<26:57,21.00s/it][01:02<26:06,20.61s/it][01:20<24:57,19.96s/it][01:35<22:10,17.98s/it][02:00<24:40,20.29s/it][02:17<23:15,19.38s/it][02:37<23:09,19.57s/it][02:55<22:17,19.11s/it][03:14<21:59,19.13s/it][03:36<22:31,19.88s/it][03:49<19:41,17.63s/it][04:13<21:33,19.60s/it][04:33<21:25,19.78s/it][05:00<23:33,22.09s/it][05:18<21:41,20.66s/it][05:37<20:55,20.26s/it][05:54<19:45,19.43s/it][06:07<17:25,17.42s/it][06:25<17:11,17.48s/it][06:49<18:46,19.43s/it][07:10<18:56,19.94s/it][07:30<18:33,19.89s/it][07:45<16:51,18.40s/it][08:10<18:24,20.46s/it][08:26<16:52,19.10s/it][08:48<17:20,20.01s/it][09:05<16:18,19.18s/it][09:28<16:57,20.36s/it][09:49<16:46,20.53s/it][10:14<17:30,21.88s/it][10:33<16:25,20.97s/it][10:57<16:42,21.78s/it][11:12<14:47,19.73s/it][11:31<14:16,19.46s/it][11:47<13:14,18.48s/it][11:58<11:24,16.31s/it][12:17<11:47,17.24s/it][12:34<11:19,16.98s/it][12:56<11:58,18.42s/it][13:12<11:15,17.79s/it][13:22<09:30,15.41s/it][13:43<10:23,17.31s/it][13:58<09:41,16.61s/it][14:21<10:20,18.26s/it][14:39<10:03,18.28s/it][14:53<09:06,17.07s/it][15:11<08:59,17.41s/it][15:25<08:06,16.20s/it][15:48<08:52,18.37s/it][16:04<08:11,17.55s/it][16:25<08:26,18.75s/it][16:44<08:08,18.79s/it][16:55<06:48,16.32s/it][17:19<07:27,18.65s/it][17:38<07:14,18.88s/it][18:01<07:18,19.93s/it][18:17<06:33,18.73s/it][18:37<06:22,19.13s/it][19:00<06:26,20.35s/it][19:11<05:17,17.62s/it][19:31<05:11,18.32s/it][19:47<04:43,17.71s/it][20:03<04:17,17.18s/it][20:27<04:27,19.09s/it][20:48<04:17,19.84s/it][21:08<03:56,19.67s/it][21:26<03:30,19.16s/it][21:49<03:24,20.47s/it][22:04<02:49,18.80s/it][22:25<02:34,19.33s/it][22:40<02:07,18.26s/it][22:59<01:49,18.27s/it][23:19<01:34,18.86s/it][23:40<01:18,19.62s/it][23:59<00:57,19.24s/it][24:13<00:35,17.84s/it][24:34<00:18,18.70s/it][24:36<00:00,13.73s/it][24:36<00:00,18.69s/it][2025/01/31 22:18:08] - pixel - Run 79: Accuracy: 0.5992
[2025/01/31 22:18:08] - pixel Mean: 0.5971, Std: 0.0020
[2025/01/31 22:18:08] - Testing done.

wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.025 MB uploadedwandb: | 0.005 MB of 0.027 MB uploadedwandb: / 0.005 MB of 0.027 MB uploadedwandb: - 0.005 MB of 0.027 MB uploadedwandb: \ 0.027 MB of 0.027 MB uploadedwandb: 
wandb: Run history:
wandb: Nature Acc Mean ‚ñÅ
wandb:  Nature Acc Std ‚ñÅ
wandb:  pixel_mean_adv ‚ñÅ
wandb:   pixel_std_adv ‚ñÅ
wandb: 
wandb: Run summary:
wandb: Nature Acc Mean 0.6479
wandb:  Nature Acc Std 0.0
wandb:  pixel_mean_adv 0.59715
wandb:   pixel_std_adv 0.00205
wandb: 
wandb: üöÄ View run deft-capybara-72 at: https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/runs/0hkvffwt
wandb: Ô∏è‚ö° View job at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjU1NDQ3MTUxMg==/version_details/v3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250131_212843-0hkvffwt/logs
