nohup: ignoring input
wandb: Currently logged in as: xuanzhu_07 (xuanzhu_07-university-of-sydney). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.3
wandb: Run data is saved locally in /home/yxma/hzx/hzx/hzx/rand_defence/wandb/run-20250131_060449-4t071wda
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-paper-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square
wandb: üöÄ View run at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/runs/4t071wda
[2025/01/31 06:04:52] - Namespace(batch_size=128, data_dir='~/datasets/CIFAR10/', dataset='cifar10', epochs=200, network='WideResNet34', worker=4, lr_schedule='multistep', lr_min=0.0, lr_max=0.1, weight_decay=0.0005, momentum=0.9, none_random_training=True, rand_deform_training=False, randpos_deform_training=True, randpos_multi_deform_training=False, is_n_repeat=False, reNum=5, only_adv_randpos_training=False, rand_path_training=False, epsilon=8, alpha=2, c=0.0001, steps=1000, seed=0, attack_iters=20, restarts=1, save_dir='logs/ResNet18_DeformableConvolution', pretrain='/home/yxma/hzx/hzx/hzx/rand_defence/ckpt/cifar10/WideResNet34/ckpt/model_20241107185544.pth', continue_training=False, lb=2048, pos=0, eot=False, bapp_iterations=1000, bapp_stepsize='geometric_progression', bapp_max_evals=100, bapp_initial_evals=100, hang=False, device=0)
[2025/01/31 06:04:52] - Dataset: cifar10
Process ID: 2968267
Pretrain model path: /home/yxma/hzx/hzx/hzx/rand_defence/ckpt/cifar10/WideResNet34/ckpt/model_20241107185544.pth
Does pretrain model path exist? True
Files already downloaded and verified
Files already downloaded and verified
WideResNet6(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock4(
    (layer): Sequential(
      (0): RandomBasicBlock2222(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): MaskedConv2d(16, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=640, out_features=10, bias=True)
  (normalize): NormalizeByChannelMeanStd(mean=tensor([0.4914, 0.4822, 0.4465], device='cuda:0'), std=tensor([0.2471, 0.2435, 0.2616], device='cuda:0'))
)[2025/01/31 06:04:55] - Evaluating with standard images with random mask...

Different keys:
normalize.mean
normalize.std
Nature:
[2025/01/31 06:04:59] - Nature Acc Mean: 0.9044, Std: 0.0000
tensor([[[[0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 0., 0., 1., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 0., 0., 1., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 0., 0., 1., 0.],
          [0., 0., 0., 0., 0.]]],


        ...,


        [[[0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 0., 0., 1., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 0., 0., 1., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 0., 0., 1., 0.],
          [0., 0., 0., 0., 0.]]]], device='cuda:0')
torch.Size([160, 1, 5, 5])
Square attacking
[00:00<?,?it/s][02:13<2:54:06,133.93s/it][04:36<2:58:43,139.26s/it][07:07<3:02:57,144.45s/it][09:45<3:07:12,149.77s/it][12:30<3:11:39,155.40s/it][14:59<3:06:20,153.15s/it][17:24<3:00:21,150.29s/it][20:09<3:03:36,155.16s/it][22:33<2:56:58,151.70s/it][25:07<2:55:08,152.30s/it][27:35<2:51:05,150.97s/it][29:58<2:46:01,148.68s/it][32:33<2:45:28,150.44s/it][35:08<2:44:33,151.90s/it][37:48<2:44:28,154.19s/it][40:10<2:38:06,150.57s/it][43:00<2:41:46,156.55s/it][45:42<2:40:47,158.16s/it][48:18<2:37:23,157.39s/it][50:33<2:28:14,150.76s/it][52:54<2:22:57,147.89s/it][55:30<2:22:53,150.41s/it][57:35<2:13:14,142.75s/it][59:07<1:56:53,127.53s/it][1:00:43<1:46:07,117.91s/it][1:02:24<1:39:48,113.00s/it][1:03:59<1:33:14,107.59s/it][1:05:31<1:27:25,102.86s/it][1:07:06<1:23:40,100.41s/it][1:08:47<1:22:13,100.68s/it][1:10:20<1:18:37,98.29s/it] [1:12:00<1:17:30,98.94s/it][1:13:32<1:14:04,96.61s/it][1:15:15<1:13:53,98.53s/it][1:16:50<1:11:34,97.61s/it][1:18:21<1:08:31,95.63s/it][1:19:58<1:07:11,95.98s/it][1:21:47<1:08:21,100.04s/it][1:23:03<1:01:51,92.79s/it] [1:24:29<58:59,90.76s/it]  [1:26:01<57:38,91.02s/it][1:27:35<56:46,92.05s/it][1:29:16<56:49,94.70s/it][1:30:50<55:09,94.55s/it][1:32:19<52:29,92.63s/it][1:33:53<51:11,93.07s/it][1:35:26<49:39,93.10s/it][1:36:52<47:02,91.05s/it][1:38:38<47:44,95.48s/it][1:40:19<47:02,97.33s/it][1:41:48<44:12,94.74s/it][1:43:13<41:19,91.84s/it][1:44:44<39:40,91.54s/it][1:46:15<38:03,91.34s/it][1:47:43<36:04,90.21s/it][1:49:17<35:02,91.41s/it][1:50:46<33:15,90.71s/it][1:52:02<30:13,86.34s/it][1:53:32<29:06,87.31s/it][1:54:57<27:29,86.82s/it][1:56:43<27:44,92.46s/it][1:58:20<26:35,93.85s/it][1:59:57<25:16,94.80s/it][2:01:16<22:30,90.03s/it][2:02:42<20:44,88.88s/it][2:04:12<19:18,89.15s/it][2:05:43<17:55,89.65s/it][2:06:59<15:43,85.78s/it][2:08:28<14:27,86.73s/it][2:10:08<13:35,90.61s/it][2:11:48<12:26,93.32s/it][2:13:27<11:06,95.14s/it][2:15:02<09:30,95.01s/it][2:16:30<07:44,92.87s/it][2:18:12<06:22,95.64s/it][2:19:56<04:54,98.07s/it][2:21:19<03:07,93.83s/it][2:23:00<01:35,95.99s/it][2:23:35<00:00,77.52s/it][2:23:35<00:00,109.06s/it][2025/01/31 08:28:35] - square - Run 79: Accuracy: 0.8210

[00:00<?,?it/s][01:25<1:50:54,85.32s/it][02:51<1:50:12,85.88s/it][04:30<1:56:26,91.92s/it][06:10<1:58:38,94.91s/it][07:55<2:01:36,98.61s/it][09:17<1:53:22,93.18s/it][10:52<1:52:29,93.75s/it][12:29<1:52:06,94.74s/it][14:05<1:51:00,95.14s/it][15:31<1:46:08,92.30s/it][17:06<1:45:25,93.02s/it][18:46<1:46:19,95.22s/it][20:13<1:41:58,92.70s/it][21:45<1:40:11,92.49s/it][23:26<1:41:24,95.07s/it][24:43<1:34:02,89.56s/it][26:25<1:36:28,93.36s/it][28:12<1:39:08,97.51s/it][29:40<1:34:27,94.45s/it][31:04<1:29:58,91.50s/it][32:37<1:28:44,91.80s/it][34:11<1:27:50,92.46s/it][35:55<1:29:39,96.06s/it][37:22<1:25:29,93.27s/it][39:00<1:25:15,94.73s/it][40:37<1:24:17,95.43s/it][42:14<1:23:08,95.94s/it][43:54<1:22:30,97.08s/it][45:35<1:21:51,98.24s/it][47:19<1:21:43,100.07s/it][48:47<1:17:09,96.44s/it] [50:24<1:15:32,96.43s/it][51:54<1:12:34,94.67s/it][53:42<1:14:01,98.71s/it][55:19<1:12:01,98.22s/it][56:39<1:06:20,92.58s/it][58:16<1:05:39,93.81s/it][1:00:06<1:07:27,98.72s/it][1:01:23<1:01:31,92.29s/it][1:02:48<58:40,90.26s/it]  [1:04:11<55:39,87.87s/it][1:05:51<56:24,91.48s/it][1:07:20<54:32,90.90s/it][1:08:50<52:47,90.51s/it][1:10:15<50:23,88.93s/it][1:11:51<50:00,90.92s/it][1:15:48<1:11:51,134.74s/it][1:19:15<1:20:55,156.63s/it][1:21:39<1:16:23,152.78s/it][1:23:21<1:06:29,137.56s/it][1:24:49<57:16,122.75s/it]  [1:26:20<50:51,113.00s/it][1:28:48<53:33,123.58s/it][1:32:31<1:03:55,153.43s/it][1:35:51<1:06:59,167.48s/it][1:37:26<55:47,145.54s/it]  [1:38:54<47:06,128.50s/it][1:40:21<40:35,115.96s/it][1:41:53<36:17,108.88s/it][1:43:16<31:59,101.04s/it][1:46:52<40:37,135.42s/it][1:50:56<47:36,168.04s/it][1:53:27<43:28,163.03s/it][1:54:46<34:28,137.88s/it][1:56:12<28:31,122.27s/it][1:57:42<24:21,112.46s/it][1:59:13<21:12,106.03s/it][2:00:32<17:56,97.88s/it] [2:02:01<15:52,95.28s/it][2:03:41<14:30,96.72s/it][2:05:23<13:05,98.18s/it][2:06:57<11:18,96.94s/it][2:08:30<09:35,95.86s/it][2:09:55<07:43,92.66s/it][2:11:39<06:23,95.91s/it][2:13:19<04:51,97.28s/it][2:14:41<03:05,92.53s/it][2:16:24<01:35,95.92s/it][2:16:58<00:00,77.33s/it][2:16:58<00:00,104.04s/it][2025/01/31 10:45:34] - square - Run 79: Accuracy: 0.8237

[00:00<?,?it/s][01:28<1:54:39,88.19s/it][02:55<1:52:10,87.41s/it][04:28<1:54:17,90.23s/it][05:58<1:52:50,90.27s/it][07:35<1:54:00,92.44s/it][09:02<1:50:12,90.58s/it][10:36<1:50:05,91.74s/it][12:16<1:51:50,94.52s/it][13:47<1:48:46,93.24s/it][15:17<1:46:18,92.45s/it][16:59<1:47:53,95.20s/it][18:37<1:47:22,96.16s/it][20:05<1:42:54,93.55s/it][21:34<1:40:03,92.37s/it][23:13<1:40:23,94.12s/it][24:31<1:33:47,89.32s/it][26:07<1:34:22,91.33s/it][27:49<1:36:07,94.54s/it][29:17<1:32:37,92.62s/it][30:41<1:28:28,89.97s/it][32:12<1:27:26,90.45s/it][33:50<1:28:03,92.68s/it][35:33<1:29:28,95.86s/it][37:00<1:25:20,93.10s/it][38:44<1:26:40,96.30s/it][40:21<1:25:11,96.45s/it][41:58<1:23:54,96.81s/it][43:31<1:21:19,95.68s/it][45:08<1:20:03,96.06s/it][46:53<1:20:34,98.66s/it][48:22<1:16:34,95.72s/it][49:47<1:12:29,92.54s/it][51:01<1:06:37,86.90s/it][52:21<1:03:46,85.03s/it][53:39<1:00:36,82.65s/it][54:48<56:28,78.81s/it]  [56:08<55:21,79.07s/it][57:35<55:43,81.54s/it][58:37<50:25,75.65s/it][59:42<47:06,72.49s/it][1:00:50<44:59,71.04s/it][1:02:08<45:08,73.19s/it][1:03:26<44:40,74.45s/it][1:04:45<44:15,75.87s/it][1:05:57<42:17,74.64s/it][1:07:10<40:52,74.31s/it][1:08:23<39:24,73.90s/it][1:09:33<37:30,72.60s/it][1:10:56<37:52,75.74s/it][1:12:18<37:32,77.66s/it][1:13:26<34:52,74.75s/it][1:14:42<33:53,75.31s/it][1:15:49<31:26,72.57s/it][1:16:57<29:46,71.45s/it][1:18:09<28:37,71.58s/it][1:19:23<27:43,72.32s/it][1:20:25<25:20,69.10s/it][1:21:29<23:39,67.60s/it][1:22:42<23:03,69.20s/it][1:23:48<21:35,68.20s/it]wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)
[1:25:13<21:59,73.31s/it][1:26:28<20:52,73.67s/it][1:27:40<19:31,73.21s/it][1:28:44<17:38,70.59s/it][1:29:53<16:22,70.18s/it][1:31:01<15:01,69.37s/it][1:32:13<14:03,70.25s/it][1:33:12<12:14,66.80s/it][1:34:17<11:03,66.38s/it][1:35:33<10:21,69.06s/it][1:36:45<09:19,69.89s/it][1:38:01<08:23,71.91s/it][1:39:18<07:21,73.53s/it][1:40:31<06:06,73.22s/it][1:41:55<05:05,76.43s/it][1:43:19<03:56,78.88s/it][1:44:24<02:29,74.61s/it][1:45:39<01:14,74.60s/it][1:46:05<00:00,60.07s/it][1:46:05<00:00,80.57s/it][2025/01/31 12:31:39] - square - Run 79: Accuracy: 0.8287
[2025/01/31 12:31:39] - square Mean: 0.8245, Std: 0.0032
[2025/01/31 12:31:39] - Testing done.

wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.026 MB uploadedwandb: / 0.005 MB of 0.026 MB uploadedwandb: - 0.005 MB of 0.026 MB uploadedwandb: \ 0.010 MB of 0.026 MB uploadedwandb: | 0.024 MB of 0.026 MB uploadedwandb: / 0.024 MB of 0.026 MB uploadedwandb: - 0.024 MB of 0.026 MB uploadedwandb: \ 0.026 MB of 0.026 MB uploadedwandb: 
wandb: Run history:
wandb: Nature Acc Mean ‚ñÅ
wandb:  Nature Acc Std ‚ñÅ
wandb: square_mean_adv ‚ñÅ
wandb:  square_std_adv ‚ñÅ
wandb: 
wandb: Run summary:
wandb: Nature Acc Mean 0.9044
wandb:  Nature Acc Std 0.0
wandb: square_mean_adv 0.82447
wandb:  square_std_adv 0.00319
wandb: 
wandb: üöÄ View run vague-paper-4 at: https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/runs/4t071wda
wandb: Ô∏è‚ö° View job at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjU1NDQ3MTUxMg==/version_details/v1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250131_060449-4t071wda/logs
