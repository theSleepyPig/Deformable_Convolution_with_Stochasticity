nohup: ignoring input
wandb: Currently logged in as: xuanzhu_07 (xuanzhu_07-university-of-sydney). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.3
wandb: Run data is saved locally in /home/yxma/hzx/hzx/hzx/rand_defence/wandb/run-20250131_210653-6o7uh37o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-violet-65
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square
wandb: üöÄ View run at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/runs/6o7uh37o
[2025/01/31 21:06:57] - Namespace(batch_size=128, data_dir='~/datasets/CIFAR10/', dataset='cifar100', epochs=200, network='WideResNet34', worker=4, lr_schedule='multistep', lr_min=0.0, lr_max=0.1, weight_decay=0.0005, momentum=0.9, none_random_training=True, rand_deform_training=False, randpos_deform_training=True, randpos_multi_deform_training=False, is_n_repeat=False, reNum=5, only_adv_randpos_training=False, rand_path_training=False, epsilon=8, alpha=2, c=0.0001, steps=1000, seed=0, attack_iters=20, restarts=1, save_dir='logs/ResNet18_DeformableConvolution', pretrain='ckpt/cifar100/WideResNet34/ckpt/model_20241107185520.pth', continue_training=False, lb=2048, pos=0, eot=False, bapp_iterations=1000, bapp_stepsize='geometric_progression', bapp_max_evals=100, bapp_initial_evals=100, hang=False, device=2)
[2025/01/31 21:06:57] - Dataset: cifar100
/home/yxma/anaconda3/envs/py39_torch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/yxma/anaconda3/envs/py39_torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Process ID: 3735111
Pretrain model path: ckpt/cifar100/WideResNet34/ckpt/model_20241107185520.pth
Does pretrain model path exist? True
Files already downloaded and verified
Files already downloaded and verified
WideResNet6(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock4(
    (layer): Sequential(
      (0): RandomBasicBlock2222(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): MaskedConv2d(16, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=640, out_features=100, bias=True)
  (normalize): NormalizeByChannelMeanStd(mean=tensor([0.4914, 0.4822, 0.4465], device='cuda:2'), std=tensor([0.2471, 0.2435, 0.2616], device='cuda:2'))
)[2025/01/31 21:07:00] - Evaluating with standard images with random mask...

Different keys:
normalize.mean
normalize.std
Nature:
[2025/01/31 21:07:03] - Nature Acc Mean: 0.6711, Std: 0.0000
tensor([[[[0., 0., 0., 0., 1.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 1., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 0., 0., 0., 1.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 1., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 0., 0., 0., 1.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 1., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        ...,


        [[[0., 0., 0., 0., 1.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 1., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 0., 0., 0., 1.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 1., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 0., 0., 0., 1.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 1., 0., 0.],
          [0., 0., 0., 0., 0.]]]], device='cuda:2')
torch.Size([160, 1, 5, 5])
Square attacking
[00:00<?,?it/s][00:41<54:13,41.71s/it][01:16<48:30,37.80s/it][01:53<47:16,37.32s/it][02:26<44:29,35.60s/it][03:01<43:41,35.43s/it][03:37<43:14,35.55s/it][04:14<43:06,35.92s/it][04:43<39:59,33.79s/it][05:19<40:15,34.51s/it][05:52<39:13,34.11s/it][06:27<38:55,34.34s/it][07:04<39:25,35.31s/it][07:38<38:15,34.77s/it][08:12<37:19,34.46s/it][08:48<37:18,34.97s/it][09:26<37:36,35.81s/it][10:02<37:14,36.04s/it][10:39<36:50,36.24s/it][11:13<35:41,35.68s/it][11:50<35:28,36.07s/it][12:26<34:37,35.82s/it][13:02<34:16,36.08s/it][13:37<33:16,35.65s/it][14:12<32:29,35.45s/it][14:47<31:54,35.46s/it][15:24<31:41,35.88s/it][16:02<31:27,36.31s/it][16:35<30:15,35.61s/it][17:10<29:28,35.36s/it][17:49<29:44,36.42s/it][18:28<29:44,37.17s/it][19:05<29:03,37.09s/it][19:41<28:08,36.70s/it][20:13<26:28,35.30s/it][20:49<26:04,35.55s/it][21:25<25:36,35.74s/it][22:00<24:48,35.44s/it][22:41<25:19,37.06s/it][23:25<26:08,39.22s/it][24:13<27:12,41.86s/it][24:57<26:55,42.51s/it][25:38<26:01,42.19s/it][26:23<25:45,42.94s/it][27:09<25:28,43.67s/it][27:55<25:15,44.57s/it][28:42<24:57,45.37s/it][29:22<23:19,43.75s/it][30:07<22:48,44.14s/it][30:50<21:50,43.70s/it][31:33<20:58,43.39s/it][32:18<20:30,43.94s/it][32:59<19:23,43.09s/it][33:49<19:35,45.23s/it][34:36<19:02,45.71s/it][35:19<17:54,44.75s/it][36:03<17:07,44.70s/it][36:48<16:22,44.65s/it][37:27<15:04,43.08s/it][38:11<14:28,43.44s/it][38:52<13:29,42.59s/it][39:36<12:55,43.06s/it][40:22<12:26,43.94s/it][41:10<12:00,45.05s/it][41:57<11:24,45.64s/it][42:40<10:28,44.88s/it][43:26<09:46,45.15s/it][44:16<09:19,46.66s/it][45:01<08:27,46.17s/it][45:52<07:57,47.76s/it][46:38<07:04,47.13s/it][47:21<06:07,45.91s/it][48:07<05:20,45.83s/it][48:50<04:29,44.99s/it][49:32<03:40,44.12s/it][50:17<02:57,44.28s/it][51:05<02:16,45.40s/it][51:53<01:32,46.16s/it][52:34<00:44,44.80s/it][52:41<00:00,33.33s/it][52:41<00:00,40.02s/it][2025/01/31 21:59:44] - square - Run 79: Accuracy: 0.5528

[00:00<?,?it/s][00:50<1:06:14,50.96s/it][01:33<59:04,46.04s/it]  [02:15<56:01,44.23s/it][02:56<53:28,42.78s/it][03:39<52:54,42.89s/it][04:22<52:31,43.17s/it][05:09<53:03,44.21s/it][05:48<50:16,42.48s/it][06:28<48:51,41.88s/it][07:07<47:05,40.95s/it][07:47<45:56,40.54s/it][08:34<47:39,42.67s/it][09:14<46:03,41.87s/it][09:55<45:01,41.57s/it][10:41<45:49,42.97s/it][11:31<47:11,44.94s/it][12:15<46:09,44.68s/it][13:00<45:33,44.81s/it][13:41<43:36,43.62s/it][14:26<43:26,44.19s/it][15:10<42:34,44.04s/it][15:54<41:51,44.06s/it][16:36<40:38,43.54s/it][17:18<39:24,42.99s/it][17:59<38:10,42.41s/it][18:40<36:55,41.81s/it][19:17<35:04,40.46s/it][19:52<32:56,38.76s/it][20:24<30:40,36.82s/it][21:01<30:00,36.74s/it][21:38<29:30,36.88s/it][22:17<29:19,37.45s/it][22:51<28:06,36.66s/it][23:23<26:18,35.07s/it][23:59<25:54,35.33s/it][24:37<25:52,36.11s/it][25:02<23:03,32.94s/it][25:35<22:25,32.83s/it][26:11<22:35,33.89s/it][26:50<22:54,35.24s/it][27:17<20:51,32.93s/it][27:49<20:07,32.63s/it][28:23<19:49,33.05s/it][28:59<19:44,33.85s/it][29:38<20:01,35.33s/it][30:14<19:41,35.80s/it][30:46<18:28,34.64s/it][31:21<17:52,34.61s/it][31:55<17:10,34.35s/it][32:29<16:35,34.34s/it][33:03<16:01,34.34s/it][33:35<15:07,33.62s/it][34:15<15:18,35.33s/it][34:54<15:11,36.47s/it][35:28<14:22,35.96s/it][36:07<14:04,36.71s/it][36:41<13:13,36.07s/it][37:12<12:05,34.53s/it][37:47<11:32,34.63s/it][38:20<10:48,34.14s/it][38:55<10:18,34.36s/it][39:31<09:51,34.77s/it][40:07<09:24,35.31s/it][40:44<08:56,35.74s/it][41:20<08:21,35.83s/it][41:57<07:48,36.07s/it][42:40<07:38,38.19s/it][43:15<06:48,37.17s/it][43:57<06:26,38.61s/it][44:32<05:38,37.61s/it][45:06<04:51,36.44s/it][45:44<04:18,36.93s/it][46:17<03:34,35.81s/it][46:52<02:57,35.50s/it][47:28<02:23,35.83s/it][48:08<01:51,37.06s/it][48:46<01:14,37.23s/it][49:19<00:35,35.97s/it][49:31<00:00,28.93s/it][49:31<00:00,37.62s/it][2025/01/31 22:49:16] - square - Run 79: Accuracy: 0.5565

[00:00<?,?it/s][00:43<56:56,43.81s/it][01:19<50:17,39.19s/it][01:56<48:12,38.07s/it][02:29<45:11,36.16s/it][03:05<44:21,35.96s/it][03:40<43:22,35.65s/it][04:17<43:25,36.19s/it][04:47<40:20,34.09s/it][05:20<39:16,33.66s/it][05:52<38:14,33.25s/it][06:24<37:23,32.99s/it][07:02<38:29,34.46s/it][07:34<36:59,33.63s/it][08:08<36:35,33.78s/it][08:44<36:44,34.44s/it][09:21<37:09,35.38s/it][09:58<37:01,35.83s/it][10:36<36:57,36.35s/it][11:10<35:46,35.78s/it][11:49<35:54,36.52s/it][12:23<34:40,35.88s/it][13:02<34:57,36.79s/it][13:36<33:42,36.11s/it][14:09<32:14,35.17s/it][14:44<31:25,34.92s/it][15:17<30:21,34.37s/it][15:53<30:14,34.90s/it][16:27<29:24,34.60s/it][17:00<28:24,34.10s/it][17:38<28:50,35.32s/it][18:15<28:42,35.88s/it][18:51<28:01,35.78s/it][19:25<27:08,35.40s/it][19:56<25:31,34.04s/it][20:30<25:02,34.15s/it][21:07<24:57,34.83s/it][21:33<22:27,32.08s/it][22:05<22:04,32.31s/it][22:42<22:26,33.67s/it][23:20<22:43,34.97s/it][23:55<22:09,34.99s/it][24:28<21:13,34.42s/it][25:03<20:38,34.39s/it][25:39<20:22,34.94s/it][26:17<20:19,35.85s/it][26:54<19:57,36.30s/it][27:25<18:23,34.50s/it][28:00<17:55,34.69s/it][28:34<17:18,34.60s/it][29:06<16:23,33.92s/it][29:42<16:02,34.36s/it]wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2 seconds.), retrying request
[30:14<15:13,33.82s/it][30:55<15:32,35.85s/it][31:34<15:23,36.93s/it][32:08<14:24,36.01s/it][32:46<13:57,36.42s/it][33:20<13:06,35.74s/it][33:51<11:59,34.25s/it][34:28<11:41,35.07s/it][35:00<10:48,34.15s/it][35:33<10:11,33.98s/it][36:09<09:48,34.60s/it][36:47<09:30,35.66s/it][37:23<08:56,35.79s/it][37:58<08:16,35.46s/it][38:33<07:38,35.28s/it][39:13<07:21,36.79s/it][39:49<06:40,36.36s/it][40:30<06:19,37.95s/it][41:07<05:39,37.70s/it][41:41<04:52,36.62s/it][42:18<04:15,36.51s/it][42:51<03:34,35.68s/it][43:27<02:57,35.54s/it][44:03<02:22,35.68s/it][44:42<01:49,36.65s/it][45:21<01:15,37.58s/it][45:53<00:35,35.92s/it][45:59<00:00,26.67s/it][45:59<00:00,34.92s/it][2025/01/31 23:35:15] - square - Run 79: Accuracy: 0.5586
[2025/01/31 23:35:15] - square Mean: 0.5560, Std: 0.0024
[2025/01/31 23:35:15] - Testing done.

wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.025 MB uploadedwandb: / 0.008 MB of 0.027 MB uploadedwandb: - 0.008 MB of 0.027 MB uploadedwandb: \ 0.008 MB of 0.027 MB uploadedwandb: | 0.027 MB of 0.027 MB uploadedwandb: / 0.027 MB of 0.027 MB uploadedwandb: - 0.027 MB of 0.027 MB uploadedwandb: \ 0.027 MB of 0.027 MB uploadedwandb: | 0.027 MB of 0.027 MB uploadedwandb: / 0.027 MB of 0.027 MB uploadedwandb: - 0.027 MB of 0.027 MB uploadedwandb: \ 0.027 MB of 0.027 MB uploadedwandb: | 0.027 MB of 0.027 MB uploadedwandb: / 0.027 MB of 0.027 MB uploadedwandb: - 0.027 MB of 0.027 MB uploadedwandb: \ 0.027 MB of 0.027 MB uploadedwandb: | 0.027 MB of 0.027 MB uploadedwandb: / 0.027 MB of 0.027 MB uploadedwandb: - 0.027 MB of 0.027 MB uploadedwandb: \ 0.027 MB of 0.027 MB uploadedwandb: 
wandb: Run history:
wandb: Nature Acc Mean ‚ñÅ
wandb:  Nature Acc Std ‚ñÅ
wandb: square_mean_adv ‚ñÅ
wandb:  square_std_adv ‚ñÅ
wandb: 
wandb: Run summary:
wandb: Nature Acc Mean 0.6711
wandb:  Nature Acc Std 0.0
wandb: square_mean_adv 0.55597
wandb:  square_std_adv 0.0024
wandb: 
wandb: üöÄ View run twilight-violet-65 at: https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/runs/6o7uh37o
wandb: Ô∏è‚ö° View job at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjU1NDQ3MTUxMg==/version_details/v4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250131_210653-6o7uh37o/logs
