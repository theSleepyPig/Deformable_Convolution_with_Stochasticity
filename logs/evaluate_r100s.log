nohup: ignoring input
wandb: Currently logged in as: xuanzhu_07 (xuanzhu_07-university-of-sydney). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.19.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.3
wandb: Run data is saved locally in /home/yxma/hzx/hzx/hzx/rand_defence/wandb/run-20250131_210712-9816ip97
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-eon-66
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square
wandb: üöÄ View run at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/runs/9816ip97
[2025/01/31 21:07:19] - Namespace(batch_size=128, data_dir='~/datasets/CIFAR10/', dataset='cifar100', epochs=200, network='ResNet18', worker=4, lr_schedule='multistep', lr_min=0.0, lr_max=0.1, weight_decay=0.0005, momentum=0.9, none_random_training=True, rand_deform_training=False, randpos_deform_training=True, randpos_multi_deform_training=False, is_n_repeat=False, reNum=5, only_adv_randpos_training=False, rand_path_training=False, epsilon=8, alpha=2, c=0.0001, steps=1000, seed=0, attack_iters=20, restarts=1, save_dir='logs/ResNet18_DeformableConvolution', pretrain='ckpt/cifar100/ResNet18/ckpt/model_20241107183716.pth', continue_training=False, lb=2048, pos=0, eot=False, bapp_iterations=1000, bapp_stepsize='geometric_progression', bapp_max_evals=100, bapp_initial_evals=100, hang=False, device=3)
[2025/01/31 21:07:19] - Dataset: cifar100
/home/yxma/anaconda3/envs/py39_torch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/yxma/anaconda3/envs/py39_torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[2025/01/31 21:07:21] - Evaluating with standard images with random mask...
Process ID: 3735695
Pretrain model path: ckpt/cifar100/ResNet18/ckpt/model_20241107183716.pth
Does pretrain model path exist? True
Files already downloaded and verified
Files already downloaded and verified
ResNetPartmask5(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): ModuleList(
    (0): RandonBasicBlock02(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): MaskedConv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential()
    )
  )
  (layer11): ModuleList(
    (0): BasicBlock(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential()
    )
  )
  (layer2): ModuleList(
    (0): BasicBlock(
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential()
    )
  )
  (layer3): ModuleList(
    (0): BasicBlock(
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential()
    )
  )
  (layer4): ModuleList(
    (0): BasicBlock(
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=100, bias=True)
  (normalize): NormalizeByChannelMeanStd(mean=tensor([0.4914, 0.4822, 0.4465], device='cuda:3'), std=tensor([0.2471, 0.2435, 0.2616], device='cuda:3'))
)
Different keys:
normalize.mean
normalize.std
Nature:
[2025/01/31 21:07:21] - Nature Acc Mean: 0.6495, Std: 0.0000
tensor([[[[0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        ...,


        [[[0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [1., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]]], device='cuda:3')
Square attacking
[00:00<?,?it/s][00:17<22:12,17.09s/it][00:33<21:07,16.45s/it][00:49<20:33,16.23s/it][01:04<20:07,16.10s/it][01:20<19:43,16.00s/it][01:36<19:30,16.03s/it][01:53<19:29,16.25s/it][02:08<18:52,15.94s/it][02:24<18:32,15.89s/it][02:41<18:37,16.20s/it][02:58<18:28,16.30s/it][03:14<18:08,16.25s/it][03:28<17:22,15.80s/it][03:45<17:14,15.91s/it][04:01<17:10,16.10s/it][04:19<17:23,16.57s/it][04:36<17:24,16.85s/it][04:49<15:53,15.63s/it][05:06<15:59,15.99s/it][05:22<15:51,16.12s/it][05:39<15:40,16.21s/it][05:55<15:30,16.33s/it][06:12<15:14,16.32s/it][06:28<15:03,16.42s/it][06:45<14:43,16.36s/it][07:01<14:29,16.41s/it][07:19<14:32,16.79s/it][07:36<14:29,17.06s/it][07:53<14:08,16.97s/it][08:08<13:19,16.31s/it][08:27<13:35,16.99s/it][08:43<13:12,16.86s/it][08:59<12:48,16.70s/it][09:16<12:30,16.67s/it][09:33<12:14,16.70s/it][09:51<12:18,17.16s/it][10:07<11:40,16.68s/it][10:24<11:37,17.01s/it][10:41<11:15,16.89s/it][10:58<10:59,16.91s/it][11:13<10:21,16.35s/it][11:26<09:24,15.27s/it][11:43<09:30,15.84s/it][12:00<09:26,16.19s/it][12:17<09:18,16.44s/it][12:34<09:05,16.53s/it][12:50<08:47,16.49s/it][13:07<08:31,16.49s/it][13:23<08:16,16.55s/it][13:40<08:02,16.63s/it][13:57<07:48,16.73s/it][14:13<07:28,16.61s/it][14:30<07:09,16.53s/it][14:47<06:55,16.64s/it][15:04<06:44,16.85s/it][15:21<06:26,16.82s/it][15:37<06:07,16.70s/it][15:55<05:59,17.11s/it][16:13<05:47,17.38s/it][16:26<05:04,16.05s/it][16:43<04:51,16.20s/it][16:59<04:36,16.28s/it][17:16<04:21,16.34s/it][17:32<04:05,16.35s/it][17:48<03:48,16.35s/it][18:05<03:32,16.32s/it][18:21<03:16,16.35s/it][18:35<02:51,15.61s/it][18:51<02:38,15.84s/it][19:08<02:24,16.00s/it][19:24<02:08,16.11s/it][19:40<01:53,16.20s/it][19:57<01:37,16.26s/it][20:13<01:21,16.31s/it][20:28<01:02,15.70s/it][20:44<00:47,15.92s/it][21:00<00:32,16.06s/it][21:17<00:16,16.12s/it][21:30<00:00,15.23s/it][21:30<00:00,16.33s/it][2025/01/31 21:28:52] - square - Run 79: Accuracy: 0.5036

[00:00<?,?it/s][00:24<32:11,24.77s/it][00:49<32:01,24.95s/it][01:16<32:36,25.74s/it][01:39<30:48,24.65s/it][02:10<33:01,26.77s/it][02:35<32:13,26.49s/it][03:04<32:28,27.07s/it][03:31<32:03,27.10s/it][03:57<31:18,26.84s/it][04:23<30:23,26.42s/it][04:50<30:17,26.73s/it][05:17<29:57,26.82s/it][05:40<28:19,25.74s/it][06:11<29:34,27.30s/it][06:41<29:51,28.00s/it][07:08<29:04,27.69s/it][07:34<28:05,27.19s/it][07:53<25:04,24.67s/it][08:21<25:47,25.79s/it][08:48<25:36,26.03s/it][09:15<25:34,26.45s/it][09:43<25:40,27.02s/it][10:11<25:14,27.04s/it][10:39<25:08,27.43s/it][11:02<23:28,26.09s/it][11:29<23:15,26.34s/it][11:55<22:46,26.28s/it][12:20<22:01,25.91s/it][12:46<21:43,26.07s/it][13:11<20:48,25.48s/it][13:37<20:33,25.70s/it][14:02<19:54,25.42s/it][14:30<20:08,26.27s/it][14:55<19:30,26.02s/it][15:22<19:09,26.13s/it][15:51<19:23,27.06s/it][16:17<18:39,26.66s/it][16:47<18:56,27.72s/it][17:14<18:28,27.72s/it][17:42<18:04,27.80s/it][18:03<16:16,25.71s/it][18:28<15:45,25.55s/it][18:55<15:33,25.93s/it][19:21<15:01,25.75s/it][19:47<14:45,26.04s/it][20:16<14:41,26.72s/it][20:42<14:07,26.49s/it][21:10<13:58,27.05s/it][21:38<13:36,27.22s/it][22:03<12:52,26.64s/it][22:31<12:38,27.08s/it][22:59<12:16,27.26s/it][23:24<11:34,26.69s/it][23:50<10:59,26.38s/it][24:17<10:42,26.75s/it][24:44<10:12,26.62s/it][25:15<10:15,27.96s/it][25:42<09:42,27.74s/it][26:08<09:03,27.18s/it][26:29<08:00,25.28s/it][26:54<07:36,25.38s/it][27:20<07:15,25.63s/it][27:48<06:57,26.10s/it][28:15<06:35,26.36s/it][28:40<06:05,26.09s/it][29:09<05:51,27.02s/it][29:35<05:19,26.65s/it][30:00<04:48,26.22s/it][30:30<04:33,27.39s/it][30:57<04:03,27.04s/it][31:22<03:33,26.66s/it][31:49<03:06,26.59s/it][32:11<02:31,25.24s/it][32:29<01:55,23.14s/it][32:47<01:25,21.45s/it][33:04<01:00,20.12s/it][33:21<00:38,19.27s/it][33:38<00:18,18.57s/it][33:45<00:00,15.26s/it][33:45<00:00,25.64s/it][2025/01/31 22:02:38] - square - Run 79: Accuracy: 0.5068

[00:00<?,?it/s][00:16<21:42,16.70s/it][00:35<22:40,17.67s/it][00:52<22:08,17.47s/it][01:07<20:50,16.67s/it][01:25<20:49,16.89s/it][01:42<20:44,17.05s/it][01:59<20:33,17.13s/it][02:16<20:20,17.19s/it][02:33<19:50,17.01s/it][02:51<19:42,17.14s/it][03:07<19:19,17.05s/it][03:26<19:38,17.58s/it][03:40<18:02,16.40s/it][03:58<18:27,17.03s/it][04:17<18:38,17.48s/it][04:35<18:36,17.72s/it][04:54<18:30,17.92s/it][05:08<17:00,16.73s/it][05:24<16:48,16.80s/it][05:41<16:26,16.72s/it][05:58<16:07,16.68s/it][06:14<15:49,16.65s/it][06:31<15:33,16.67s/it][06:48<15:25,16.83s/it][07:05<15:10,16.85s/it][07:19<14:13,16.11s/it][07:36<14:05,16.25s/it][07:52<13:43,16.14s/it][08:09<13:35,16.31s/it][08:25<13:25,16.43s/it][08:42<13:17,16.61s/it][09:01<13:29,17.22s/it][09:18<13:07,17.12s/it][09:33<12:30,16.67s/it][09:50<12:13,16.67s/it][10:07<11:57,16.69s/it][10:19<10:47,15.42s/it][10:36<10:49,15.84s/it][10:53<10:48,16.22s/it][11:10<10:38,16.36s/it][11:23<09:49,15.51s/it][11:39<09:29,15.41s/it][11:55<09:28,15.80s/it][12:12<09:21,16.06s/it][12:30<09:29,16.74s/it][12:47<09:11,16.70s/it][13:00<08:20,15.63s/it][13:18<08:28,16.41s/it][13:37<08:34,17.17s/it][13:55<08:20,17.26s/it][14:11<07:57,17.06s/it][14:30<07:52,17.50s/it][14:47<07:31,17.35s/it][15:03<07:08,17.15s/it][15:20<06:45,16.88s/it][15:36<06:25,16.76s/it][15:54<06:12,16.93s/it][16:11<06:00,17.16s/it][16:28<05:41,17.08s/it][16:42<05:03,15.97s/it][16:58<04:49,16.11s/it][17:15<04:37,16.34s/it][17:28<04:08,15.53s/it][17:46<04:00,16.05s/it][18:03<03:49,16.38s/it][18:20<03:34,16.47s/it][18:36<03:17,16.48s/it][18:49<02:50,15.53s/it][19:07<02:40,16.07s/it][19:24<02:27,16.38s/it][19:41<02:12,16.59s/it][19:58<01:56,16.68s/it][20:14<01:39,16.61s/it][20:30<01:22,16.51s/it][20:47<01:05,16.50s/it][21:04<00:50,16.80s/it][21:22<00:33,16.94s/it][21:38<00:16,16.81s/it][21:45<00:00,13.85s/it][21:45<00:00,16.53s/it][2025/01/31 22:24:24] - square - Run 79: Accuracy: 0.5049
[2025/01/31 22:24:24] - square Mean: 0.5051, Std: 0.0013
[2025/01/31 22:24:24] - Testing done.

wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.026 MB uploadedwandb: | 0.018 MB of 0.029 MB uploadedwandb: / 0.018 MB of 0.029 MB uploadedwandb: - 0.018 MB of 0.029 MB uploadedwandb: \ 0.029 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedwandb: 
wandb: Run history:
wandb: Nature Acc Mean ‚ñÅ
wandb:  Nature Acc Std ‚ñÅ
wandb: square_mean_adv ‚ñÅ
wandb:  square_std_adv ‚ñÅ
wandb: 
wandb: Run summary:
wandb: Nature Acc Mean 0.6495
wandb:  Nature Acc Std 0.0
wandb: square_mean_adv 0.5051
wandb:  square_std_adv 0.00131
wandb: 
wandb: üöÄ View run autumn-eon-66 at: https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/runs/9816ip97
wandb: Ô∏è‚ö° View job at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjU1NDQ3MTUxMg==/version_details/v4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250131_210712-9816ip97/logs
