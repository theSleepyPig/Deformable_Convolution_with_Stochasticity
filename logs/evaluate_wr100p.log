nohup: ignoring input
wandb: Currently logged in as: xuanzhu_07 (xuanzhu_07-university-of-sydney). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.19.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.3
wandb: Run data is saved locally in /home/yxma/hzx/hzx/hzx/rand_defence/wandb/run-20250131_212856-dhf3xwau
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-terrain-73
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square
wandb: üöÄ View run at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/runs/dhf3xwau
[2025/01/31 21:29:00] - Namespace(batch_size=128, data_dir='~/datasets/CIFAR10/', dataset='cifar100', epochs=200, network='WideResNet34', worker=4, lr_schedule='multistep', lr_min=0.0, lr_max=0.1, weight_decay=0.0005, momentum=0.9, none_random_training=True, rand_deform_training=False, randpos_deform_training=True, randpos_multi_deform_training=False, is_n_repeat=False, reNum=5, only_adv_randpos_training=False, rand_path_training=False, epsilon=8, alpha=2, c=0.0001, steps=1000, seed=0, attack_iters=20, restarts=1, save_dir='logs/ResNet18_DeformableConvolution', pretrain='ckpt/cifar100/WideResNet34/ckpt/model_20241107185520.pth', continue_training=False, lb=2048, pos=0, eot=False, bapp_iterations=1000, bapp_stepsize='geometric_progression', bapp_max_evals=100, bapp_initial_evals=100, hang=False, device=3)
[2025/01/31 21:29:00] - Dataset: cifar100
/home/yxma/anaconda3/envs/py39_torch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/yxma/anaconda3/envs/py39_torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Process ID: 3755619
Pretrain model path: ckpt/cifar100/WideResNet34/ckpt/model_20241107185520.pth
Does pretrain model path exist? True
Files already downloaded and verified
Files already downloaded and verified
WideResNet6(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock4(
    (layer): Sequential(
      (0): RandomBasicBlock2222(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): MaskedConv2d(16, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=640, out_features=100, bias=True)
  (normalize): NormalizeByChannelMeanStd(mean=tensor([0.4914, 0.4822, 0.4465], device='cuda:3'), std=tensor([0.2471, 0.2435, 0.2616], device='cuda:3'))
)[2025/01/31 21:29:03] - Evaluating with standard images with random mask...

Different keys:
normalize.mean
normalize.std
Nature:
[2025/01/31 21:29:06] - Nature Acc Mean: 0.6704, Std: 0.0000
tensor([[[[0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 1.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 1.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 1.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        ...,


        [[[0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 1.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 1.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]],


        [[[0., 1., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 1.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]]], device='cuda:3')
torch.Size([160, 1, 5, 5])
Pixel attacking
[00:00<?,?it/s]/home/yxma/anaconda3/envs/py39_torch/lib/python3.9/site-packages/torchattacks/attacks/_differential_evolution.py:592: RuntimeWarning: divide by zero encountered in scalar divide
  convergence=self.tol / convergence) is True):
[00:12<16:06,12.40s/it][00:25<16:26,12.82s/it][00:38<16:04,12.69s/it][00:49<15:11,12.15s/it][00:58<13:50,11.23s/it][01:11<14:22,11.82s/it][01:23<13:59,11.66s/it][01:34<13:37,11.51s/it][01:44<13:00,11.15s/it][01:56<12:55,11.24s/it][02:09<13:23,11.81s/it][02:21<13:27,12.05s/it][02:34<13:19,12.12s/it][02:44<12:31,11.57s/it][02:57<12:40,11.88s/it][03:09<12:37,12.02s/it][03:21<12:26,12.04s/it][03:35<12:41,12.48s/it][03:46<12:11,12.19s/it][03:59<12:10,12.38s/it][04:11<11:54,12.31s/it][04:24<11:50,12.47s/it][04:36<11:30,12.32s/it][04:48<11:08,12.15s/it][05:00<10:53,12.10s/it][05:11<10:30,11.90s/it][05:22<10:04,11.63s/it][05:33<09:41,11.41s/it][05:44<09:28,11.37s/it][05:56<09:24,11.51s/it][06:10<09:41,12.12s/it][06:21<09:26,12.05s/it][06:34<09:20,12.18s/it][06:46<09:04,12.10s/it][06:59<09:07,12.45s/it][07:11<08:47,12.26s/it][07:24<08:42,12.44s/it][07:35<08:13,12.03s/it][07:49<08:20,12.52s/it][08:00<08:01,12.35s/it][08:13<07:56,12.54s/it][08:25<07:35,12.31s/it][08:37<07:16,12.12s/it][08:49<07:06,12.20s/it][09:00<06:37,11.69s/it][09:13<06:42,12.19s/it][09:23<06:11,11.62s/it][09:35<05:56,11.49s/it][09:46<05:41,11.37s/it][09:58<05:37,11.65s/it][10:11<05:36,12.03s/it][10:22<05:15,11.70s/it][10:36<05:22,12.41s/it][10:49<05:17,12.72s/it][11:01<05:00,12.52s/it][11:13<04:37,12.08s/it][11:26<04:36,12.56s/it][11:38<04:16,12.23s/it][11:50<04:06,12.33s/it][12:02<03:51,12.18s/it][12:14<03:39,12.17s/it][12:27<03:30,12.36s/it][12:41<03:24,12.75s/it][12:53<03:11,12.76s/it][13:06<02:59,12.84s/it][13:19<02:46,12.78s/it][13:34<02:41,13.44s/it][13:47<02:26,13.34s/it][13:59<02:10,13.03s/it][14:10<01:51,12.41s/it][14:22<01:36,12.02s/it][14:33<01:23,11.87s/it][14:45<01:11,11.93s/it][14:57<00:59,11.93s/it][15:11<00:50,12.60s/it][15:24<00:37,12.63s/it][15:36<00:25,12.59s/it][15:49<00:12,12.44s/it][15:50<00:00, 9.16s/it][15:50<00:00,12.03s/it][2025/01/31 21:44:57] - pixel - Run 79: Accuracy: 0.6041

[00:00<?,?it/s][00:11<14:45,11.35s/it][00:24<16:00,12.47s/it][00:36<15:22,12.13s/it][00:48<14:59,11.99s/it][00:58<14:08,11.47s/it][01:10<13:56,11.46s/it][01:23<14:21,11.96s/it][01:33<13:43,11.60s/it][01:45<13:27,11.53s/it][01:57<13:40,11.89s/it][02:10<13:49,12.21s/it][02:22<13:15,11.87s/it][02:34<13:17,12.08s/it][02:45<12:47,11.81s/it][02:59<13:10,12.35s/it][03:13<13:24,12.77s/it][03:26<13:20,12.92s/it][03:38<12:44,12.54s/it][03:50<12:22,12.38s/it][04:01<12:01,12.24s/it][04:12<11:18,11.69s/it][04:25<11:35,12.20s/it][04:37<11:18,12.11s/it][04:49<11:05,12.09s/it][05:01<10:53,12.11s/it][05:13<10:39,12.08s/it][05:25<10:25,12.02s/it][05:37<10:07,11.90s/it][05:49<10:01,12.02s/it][06:03<10:09,12.44s/it][06:15<10:03,12.58s/it][06:26<09:23,11.99s/it][06:38<09:10,11.98s/it][06:50<08:53,11.85s/it][07:04<09:09,12.49s/it][07:16<08:50,12.35s/it][07:29<08:47,12.57s/it][07:41<08:27,12.39s/it][07:54<08:23,12.60s/it][08:05<08:00,12.32s/it][08:18<07:51,12.42s/it][08:30<07:30,12.16s/it][08:42<07:15,12.11s/it][08:53<06:55,11.87s/it][09:04<06:37,11.68s/it][09:18<06:46,12.33s/it][09:29<06:24,12.02s/it][09:42<06:14,12.08s/it][09:54<06:05,12.19s/it][10:07<06:00,12.44s/it][10:20<05:54,12.66s/it][10:34<05:50,12.98s/it][10:46<05:34,12.85s/it][11:00<05:28,13.16s/it][11:12<05:08,12.84s/it][11:24<04:50,12.61s/it][11:37<04:34,12.49s/it][11:48<04:11,11.99s/it][11:59<03:59,11.96s/it][12:12<03:49,12.10s/it][12:24<03:35,11.99s/it][12:37<03:30,12.39s/it][12:49<03:16,12.26s/it][13:01<03:01,12.13s/it][13:13<02:52,12.29s/it][13:26<02:42,12.53s/it][13:40<02:34,12.89s/it][13:52<02:18,12.62s/it][14:04<02:05,12.54s/it][14:16<01:49,12.21s/it][14:26<01:32,11.60s/it][14:40<01:25,12.18s/it][14:52<01:13,12.17s/it][15:04<01:01,12.21s/it][15:17<00:49,12.36s/it][15:31<00:38,12.85s/it][15:42<00:24,12.43s/it][15:55<00:12,12.63s/it][15:57<00:00, 9.34s/it][15:57<00:00,12.12s/it][2025/01/31 22:00:55] - pixel - Run 79: Accuracy: 0.6017
[2025/01/31 22:00:55] - pixel Mean: 0.6029, Std: 0.0012
[2025/01/31 22:00:55] - Testing done.

wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.008 MB uploadedwandb: \ 0.025 MB of 0.027 MB uploadedwandb: | 0.025 MB of 0.027 MB uploadedwandb: / 0.025 MB of 0.027 MB uploadedwandb: - 0.027 MB of 0.027 MB uploadedwandb: 
wandb: Run history:
wandb: Nature Acc Mean ‚ñÅ
wandb:  Nature Acc Std ‚ñÅ
wandb:  pixel_mean_adv ‚ñÅ
wandb:   pixel_std_adv ‚ñÅ
wandb: 
wandb: Run summary:
wandb: Nature Acc Mean 0.6704
wandb:  Nature Acc Std 0.0
wandb:  pixel_mean_adv 0.6029
wandb:   pixel_std_adv 0.0012
wandb: 
wandb: üöÄ View run visionary-terrain-73 at: https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/runs/dhf3xwau
wandb: Ô∏è‚ö° View job at https://wandb.ai/xuanzhu_07-university-of-sydney/-Test-square/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjU1NDQ3MTUxMg==/version_details/v3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250131_212856-dhf3xwau/logs
